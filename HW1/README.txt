This is the README file for A00000000X's submission

== Python Version ==

I'm (We're) using Python Version 2.7.10 for
this assignment.

== General Notes about this assignment ==

----General Algorithm for generation of Language Model----

1)NLTK library was used to help me generate the probabilistic language model.
  To build a probabilistic language model, a count model will first be built
  with the FreqDist() class, before passing it as a parameter into the constructor
  of the LaplaceProbDist() class. This will then help us generate a probabilistic
  model with add-one smoothing

2)In addition to the above, I also keep tracked of all observed character fourGramsList
  separately from the actual probabilistic model. This is because the implementation
  of LaplaceProbDist does not support the storage of a four grams that is not
  contained within a model, but found within another. Therefore, in order to perform
  add-one smoothing correctly and also identify which four grams are not observed,
  the build_LM function will return another set of all observed four grams

3)Punctuations will not be removed, but all characters will be lower-cased when we are generating
  the ngrams.

4)Start and End symbols will not be added when generating the ngrams.

----General Algorithm for testing of Language Model----

1)The four grams of the string to be tested will first be generated, and then product of
  the probabilities of each four gram will be calculated. The language model that returns
  the largest product will be regarded as the most likely language for the tested string.

2)The 'multiplication' of the probabilities will be done through the summation of logarithms.
  This is because probabilities are <= 1 and multiplying multiple probabilities together
  results in a very small value which can only be represented as a 0 in the program.
  This makes differentiating the probabilities of a string between models impossible.
  This is especially so when the string we are testing is long.

3)There are cases where some four grams generated by the test string is not being observed in
  any language model. In such cases, the four grams will be excluded from the calculation
  of the probabilities as required.

4)To determine which language a test string belongs to, other than comparing the probabilities, there
  is also an additional criteria, and that is at least 1/4 of the four grams generated by the
  test string must be found within the Language Model of interest. In the case where more than
  3/4 of the four grams could not be found for any of the existing Language Models, the test string
  will be placed under the 'other' category.

== Files included with this submission ==

README.txt - This file.
build_test_LM.py - The Main Implementation. How this program was supposed to be used remains unchanged.


== Statement of individual work ==

Please initial one of the following statements.

[X] I, A00000000X, certify that I have followed the CS 3245 Information
Retrieval class guidelines for homework assignments.  In particular, I
expressly vow that I have followed the Facebook rule in discussing
with others in doing the assignment and did not take notes (digital or
printed) from the discussions.

[ ] I, A0000000X, did not follow the class rules regarding homework
assignment, because of the following reason:

<Please fill in>

I suggest that I should be graded as follows:

<Please fill in>

== References ==

Documentations for NLTK: https://www.nltk.org/index.html
Several StackOverflow discussions on how to use NLTK in python.
